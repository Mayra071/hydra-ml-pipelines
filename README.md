# ğŸ—ï¸ ML Training Pipeline

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/) [![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)](https://scikit-learn.org/stable/) [![MLflow](https://img.shields.io/badge/MLflow-2.0%2B-red)](https://mlflow.org/) [![Hydra](https://img.shields.io/badge/Hydra-1.3%2B-green)](https://hydra.cc/)


## An **end-to-end machine learning training pipeline** for the California Housing dataset featuring configurable workflows, experiment tracking, and modular components.

ğŸš€ Features
ğŸ”§ Configurable Tasks: Support for both regression (predicting median house value) and classification (price categories)

ğŸ§© Modular Pipeline: Separate components for data ingestion, preprocessing, model training, and evaluation

ğŸ¤– Multiple Models: Random Forest, Logistic Regression, Gradient Boosting with hyperparameter tuning

ğŸ“Š Experiment Tracking: Comprehensive MLflow integration for metrics, parameters, and artifacts

âš¡ Automated Preprocessing: Smart handling of missing values, scaling, and encoding based on configuration

ğŸ“ˆ Performance Monitoring: Cross-validation with multiple scoring metrics
```
ml-training-pipeline/
â”œâ”€â”€ ğŸ“‚ configs/                 # Hydra configuration files
â”‚   â”œâ”€â”€ config.yaml            # Main configuration
â”‚   â”œâ”€â”€ ğŸ“‚ dataset/            # Dataset-specific configs
â”‚   â”œâ”€â”€ ğŸ“‚ model/              # Model hyperparameters
â”‚   â”œâ”€â”€ ğŸ“‚ preprocessing/      # Preprocessing strategies
â”‚   â””â”€â”€ ğŸ“‚ training/           # Training parameters
â”œâ”€â”€ ğŸ“‚ src/Training_pipeline/  # Core pipeline code
â”‚   â”œâ”€â”€ ğŸ“‚ components/         # Data ingestion, transformation, training
â”‚   â””â”€â”€ ğŸ“‚ pipeline/           # Pipeline orchestration
â”œâ”€â”€ ğŸ“‚ artifacts/              # Processed data & preprocessing objects
â”œâ”€â”€ ğŸ“‚ models/                 # Saved trained models
â”œâ”€â”€ ğŸ“‚ mlruns/                 # MLflow experiment tracking
â”œâ”€â”€ ğŸ“‚ logs/                   # Training logs
â””â”€â”€ ğŸ“‚ tests/                  # Test cases
```

## ğŸ› ï¸ Workflow Diagram

```mermaid
flowchart LR
    A[ğŸ“‚ Data Source<br/>California Housing CSV] --> B[ğŸ“¥ Data Ingestion]
    B --> C[ğŸ§¹ Preprocessing<br/>Imputation â€¢ Scaling â€¢ Encoding]
    C --> D[ğŸ¤– Model Training<br/>Random Forest / Logistic Regression / Gradient Boosting]
    D --> E[âš¡ Hyperparameter Tuning<br/>GridSearchCV / RandomizedSearchCV]
    E --> F[ğŸ“ˆ Evaluation<br/>Cross-Validation â€¢ Metrics]
    F --> G[ğŸ“Š MLflow Tracking<br/>Params â€¢ Metrics â€¢ Artifacts â€¢ Models]
    G --> H[ğŸ’¾ Outputs<br/>Artifacts â€¢ Logs â€¢ Models]
```

## ğŸ’» Installation
### Prerequisites
- Python 3.8+  
- pip package manager  
### Step-by-Step Setup
## Clone the repository
git clone <repository-url>
cd ml-training-pipeline

## Create virtual environment
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

## Install dependencies
pip install -r requirements.txt

### Prepare the Dataset
- Download the California Housing dataset.  
- Place it at: Data_Set\\housing.csv *(or update path in config)*  
- Optional: use built-in dataset loader in src/utils.py.

## ğŸƒ Quick Start
### Regression (Default: Random Forest)
python main.py

### Classification (Logistic Regression)
python main.py dataset.task_type=classification model=logistic_regression

### View Results in MLflow
mlflow ui --backend-store-uri mlruns/
Open [http://localhost:5000](http://localhost:5000) in browser.

## âš™ï¸ Configuration
### Dataset Config
```
dataset:
  name: "california_housing"
  task_type: "regression"  # or "classification"
  target_column: "median_house_value"
  test_size: 0.2
  random_state: 42

### Model Options
- random_forest â†’ Tree-based ensemble  
- logistic_regression â†’ Linear classifier  
- gradient_boosting â†’ Boosted ensemble  

### Preprocessing Config
preprocessing:
  numeric:
    imputer: "median"
    scaler: "standard"   # standard, minmax, robust
  categorical:
    encoder: "onehot"
```

## ğŸ“š Usage Examples
```
# Gradient Boosting for regression

python main.py model.model.type=gradient_boosting
# Custom hyperparameters
python main.py 

# Classification / Regression 
python main.py dataset.task_type=Y model.model.type= X
## Advanced
python main.py preprocessing.numeric.scaler=minmax preprocessing.categorical.encoder=ordinal

python main.py dataset.test_size=0.3 training.cv_folds=3
```

## ğŸ“Š Outputs
- artifacts/ â†’ processed datasets, preprocessing objects, metrics  
- models/ â†’ trained models (.pkl)  
- logs/ â†’ detailed training logs  
- mlruns/ â†’ MLflow experiment tracking  

## ğŸ”¬ MLflow Tracking

mlflow ui --backend-store-uri mlruns/
mlflow ui --backend-store-uri mlruns/ --experiment-name "housing_prediction"

## ğŸ› Troubleshooting
```bash
# Dataset not found
python main.py paths.dataset_path="/new/path/housing.csv"

# Memory issues
python main.py dataset.test_size=0.1 model.random_forest.hyperparameters.max_depth=10

# MLflow errors
rm -rf mlruns/
python main.py

# Debug mode
python main.py logging.level=DEBUG
```
ğŸ“„ License
This project is licensed under the MIT License.

ğŸ™ Acknowledgments
Name: Manish Kumar
California Housing Dataset: UCI Machine Learning Repository

Hydra: Flexible configuration management

MLflow: Machine learning lifecycle management

Scikit-learn: Machine learning algorithms and utilities

Need Help? Check the troubleshooting section or examine generated log files.

Found a Bug? Please open an issue with configuration used and error details.
