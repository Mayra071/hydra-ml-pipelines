# Writing the polished README content to a markdown file

# ğŸ—ï¸ ML Training Pipeline

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)  
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)](https://scikit-learn.org/stable/)  
[![MLflow](https://img.shields.io/badge/MLflow-2.0%2B-red)](https://mlflow.org/)  
[![Hydra](https://img.shields.io/badge/Hydra-1.3%2B-green)](https://hydra.cc/)

An **end-to-end machine learning training pipeline** for the California Housing dataset featuring configurable workflows, experiment tracking, and modular components.

## ğŸ“‹ Table of Contents
- [ğŸš€ Features](#-features)  
- [ğŸ“ Project Structure](#-project-structure)  
- [ğŸ› ï¸ Workflow Diagram](#-workflow-diagram)  
- [ğŸ’» Installation](#-installation)  
- [ğŸƒ Quick Start](#-quick-start)  
- [âš™ï¸ Configuration](#-configuration)  
- [ğŸ“š Usage Examples](#-usage-examples)  
- [ğŸ“Š Outputs](#-outputs)  
- [ğŸ”¬ MLflow Tracking](#-mlflow-tracking)  
- [ğŸ› Troubleshooting](#-troubleshooting)  
- [ğŸ¤ Contributing](#-contributing)  
- [ğŸ“„ License](#-license)  
- [ğŸ™ Acknowledgments](#-acknowledgments)  

## ğŸš€ Features
- ğŸ”§ **Configurable Tasks**: Regression (predicting median house value) and classification (price categories).  
- ğŸ§© **Modular Pipeline**: Separate components for data ingestion, preprocessing, model training, and evaluation.  
- ğŸ¤– **Multiple Models**: Random Forest, Logistic Regression, Gradient Boosting with hyperparameter tuning.  
- ğŸ“Š **Experiment Tracking**: MLflow integration for metrics, parameters, and artifacts.  
- âš¡ **Automated Preprocessing**: Smart handling of missing values, scaling, and encoding based on configuration.  
- ğŸ“ˆ **Performance Monitoring**: Cross-validation with multiple scoring metrics.  

## ğŸ’» Installation
### Prerequisites
- Python 3.8+  
- pip package manager  

### Step-by-Step Setup
\`\`\`bash
# Clone the repository
git clone <repository-url>
cd ml-training-pipeline

# Create virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
\`\`\`

### Prepare the Dataset
- Download the California Housing dataset.  
- Place it at: C:\\Company\\Data_Set\\housing.csv *(or update path in config)*  
- Optional: use built-in dataset loader in src/utils.py.

## ğŸƒ Quick Start
### Regression (Default: Random Forest)
\`\`\`bash
python main.py
\`\`\`

### Classification (Logistic Regression)
\`\`\`bash
python main.py dataset.task_type=classification model=logistic_regression
\`\`\`

### View Results in MLflow
\`\`\`bash
mlflow ui --backend-store-uri mlruns/
\`\`\`
Open [http://localhost:5000](http://localhost:5000) in browser.

## âš™ï¸ Configuration
### Dataset Config
\`\`\`yaml
dataset:
  name: "california_housing"
  task_type: "regression"  # or "classification"
  target_column: "median_house_value"
  test_size: 0.2
  random_state: 42
\`\`\`

### Model Options
- random_forest â†’ Tree-based ensemble  
- logistic_regression â†’ Linear classifier  
- gradient_boosting â†’ Boosted ensemble  

### Preprocessing Config
\`\`\`yaml
preprocessing:
  numeric:
    imputer: "median"
    scaler: "standard"   # standard, minmax, robust
  categorical:
    encoder: "onehot"
\`\`\`

## ğŸ“š Usage Examples
### Regression
\`\`\`bash
python main.py model.model.type=gradient_boosting
python main.py model.random_forest.hyperparameters.n_estimators=500
\`\`\`

### Classification
\`\`\`bash
python main.py dataset.task_type=classification dataset.classification.n_quantiles=3
python main.py training.scoring.classification='["accuracy","f1_macro"]'
\`\`\`

### Advanced
\`\`\`bash
python main.py preprocessing.numeric.scaler=minmax preprocessing.categorical.encoder=ordinal
python main.py dataset.test_size=0.3 training.cv_folds=3
\`\`\`

## ğŸ“Š Outputs
- artifacts/ â†’ processed datasets, preprocessing objects, metrics  
- models/ â†’ trained models (.pkl)  
- logs/ â†’ detailed training logs  
- mlruns/ â†’ MLflow experiment tracking  

## ğŸ”¬ MLflow Tracking
\`\`\`bash
mlflow ui --backend-store-uri mlruns/
mlflow ui --backend-store-uri mlruns/ --experiment-name "housing_prediction"
\`\`\`

## ğŸ› Troubleshooting
```bash
# Dataset not found
python main.py paths.dataset_path="/new/path/housing.csv"

# Memory issues
python main.py dataset.test_size=0.1 model.random_forest.hyperparameters.max_depth=10

# MLflow errors
rm -rf mlruns/
python main.py

# Debug mode
python main.py logging.level=DEBUG


